<ol>
<li>
  About this Book <font size=-1>(612 words)</font>
  <ul>
    <li>How to Use this Book</li>
    <li>Why Another Textbook?</li>
    <li>Organization and Auxilary Material</li>
    <li>Acknowledgements</li>
  </ul>
</li>
<li>
  Decision Trees <font size=-1>(7508 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain the difference between memorization and generalization. </li>
        <li> Define ``inductive bias'' and recognize the role of inductive bias in learning. </li>
        <li> Take a concrete task and cast it as a learning problem, with a formal notion of input space, features, output space, generating distribution and loss function. </li>
        <li> Illustrate how regularization trades off between underfitting and overfitting. </li>
        <li> Evaluate whether a use of test data is ``cheating'' or not. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>What Does it Mean to Learn?</li>
    <li>Some Canonical Learning Problems</li>
    <li>The Decision Tree Model of Learning</li>
    <li>Formalizing the Learning Problem</li>
    <li>Inductive Bias: What We Know Before the Data Arrives</li>
    <li>Not Everything is Learnable</li>
    <li>Underfitting and Overfitting</li>
    <li>Separation of Training and Test Data</li>
    <li>Models, Parameters and Hyperparameters</li>
    <li>Chapter Summary and Outlook</li>
    <li>Decision Trees with Real-Valued Features</li>
  </ul>
</li>
<li>
  Geometry and Nearest Neighbors <font size=-1>(6215 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Describe a data set as points in a high dimensional space. </li>
        <li> Explain the curse of dimensionality. </li>
        <li> Compute distances between points in high dimensional space. </li>
        <li> Implement a K-nearest neighbor model of learning. </li>
        <li> Draw decision boundaries. </li>
        <li> Implement the K-means algorithm for clustering. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>From Data to Feature Vectors</li>
    <li>K-Nearest Neighbors</li>
    <li>Decision Boundaries</li>
    <li>K-Means Clustering</li>
    <li>Warning: High Dimensions are Scary</li>
    <li>Extensions to KNN</li>
  </ul>
</li>
<li>
  The Perceptron <font size=-1>(6001 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Describe the biological motivation behind the perceptron. </li>
        <li> Classify learning algorithms based on whether they are error-driven or not. </li>
        <li> Implement the perceptron algorithm for binary classification. </li>
        <li> Draw perceptron weight vectors and the corresponding decision boundaries in two dimensions. % </li>
        <li> Define linear separability, and be able to turn any arbitrary % data set into a linearly separable data set. </li>
        <li> Contrast the decision boundaries of decision trees, nearest neighbor algorithms and perceptrons. </li>
        <li> Compute the margin of a given weight vector on a given data set. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Bio-inspired Learning</li>
    <li>Error-Driven Updating: The Perceptron Algorithm</li>
    <li>Geometric Intrepretation</li>
    <li>Interpreting Perceptron Weights</li>
    <li>Perceptron Convergence and Linear Separability</li>
    <li>Improved Generalization: Voting and Averaging</li>
    <li>Limitations of the Perceptron</li>
  </ul>
</li>
<li>
  Practical Issues <font size=-1>(8051 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Translate between a problem description and a concrete learning problem. </li>
        <li> Perform basic feature engineering on image and text data. </li>
        <li> Explain how to use cross-validation to tune hyperparameters and estimate future performance. </li>
        <li> Compare and contrast the differences between several evaluation metrics. </li>
        <li> Explain why feature combinations are important for learning with some models but not others. </li>
        <li> Explain the relationship between the three learning techniques you have seen so far. </li>
        <li> Apply several debugging techniques to learning algorithms. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>The Importance of Good Features</li>
    <li>Irrelevant and Redundant Features</li>
    <li>Feature Pruning and Normalization</li>
    <li>Combinatorial Feature Explosion</li>
    <li>Evaluating Model Performance</li>
    <li>Cross Validation</li>
    <li>Hypothesis Testing and Statistical Significance</li>
    <li>Debugging Learning Algorithms</li>
    <li>Human Knowledge is Everywhere</li>
  </ul>
</li>
<li>
  Beyond Binary Classification <font size=-1>(6518 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Represent complex prediction problems in a formal learning setting. </li>
        <li> Be able to artifically ``balance'' imbalanced data. </li>
        <li> Understand the positive and negative aspects of several reductions from multiclass classification to binary classification. </li>
        <li> Recognize the difference between regression and ordinal regression. </li>
        <li> Implement stacking as a method of collective classification. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Learning with Imbalanced Data</li>
    <li>Multiclass Classification</li>
    <li>Ranking</li>
    <li>Collective Classification</li>
  </ul>
</li>
<li>
  Linear Models <font size=-1>(7438 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Define and plot four surrogate loss functions: squared loss, logistic loss, exponential loss and hinge loss. </li>
        <li> Compare and contrast the optimization of 0/1 loss and surrogate loss functions. </li>
        <li> Solve the optimization problem for squared loss with a quadratic regularizer in closed form. </li>
        <li> Implement and debug gradient descent and subgradient descent. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>The Optimization Framework for Linear Models</li>
    <li>Convex Surrogate Loss Functions</li>
    <li>Weight Regularization</li>
    <li>Optimization with Gradient Descent</li>
    <li>From Gradients to Subgradients</li>
    <li>Closed-form Optimization for Squared Loss</li>
    <li>Support Vector Machines</li>
  </ul>
</li>
<li>
  Probabilistic Modeling <font size=-1>(4830 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Define the generative story for a naive Bayes classifier. </li>
        <li> Derive relative frequency as the solution to a constrained optimization problem. </li>
        <li> Compare and contrast generative, conditional and discriminative learning. </li>
        <li> Explain when generative models are likely to fail. </li>
        <li> Derive logistic loss with an \ell_2 regularizer from a probabilistic perspective. % </li>
        <li> Explain the maximum entropy principle and relate it to logistic % regression. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Classification by Density Estimation</li>
    <li>Statistical Estimation</li>
    <li>Naive Bayes Models</li>
    <li>Prediction</li>
    <li>Generative Stories</li>
    <li>Conditional Models</li>
    <li>Regularization via Priors</li>
    <li>Maximum Entropy Principle</li>
  </ul>
</li>
<li>
  Neural Networks <font size=-1>(5054 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain the biological inspiration for multi-layer neural networks. </li>
        <li> Construct a two-layer network that can solve the XOR problem. </li>
        <li> Implement the back-propogation algorithm for training multi-layer networks. </li>
        <li> Explain the trade-off between depth and breadth in network structure. </li>
        <li> Contrast neural networks with radial basis functions with k-nearest neighbor learning. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Bio-inspired Multi-Layer Networks</li>
    <li>The Back-propagation Algorithm</li>
    <li>Initialization and Convergence of Neural Networks</li>
    <li>Beyond Two Layers</li>
    <li>Breadth versus Depth</li>
    <li>Basis Functions</li>
  </ul>
</li>
<li>
  Kernel Methods <font size=-1>(5056 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain how kernels generalize both feature combinations and basis functions. </li>
        <li> Contrast dot products with kernel products. </li>
        <li> Implement kernelized perceptron. </li>
        <li> Derive a kernelized version of regularized least squares regression. </li>
        <li> Implement a kernelized version of the perceptron. </li>
        <li> Derive the dual formulation of the support vector machine. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>From Feature Combinations to Kernels</li>
    <li>Kernelized Perceptron</li>
    <li>Kernelized K-means</li>
    <li>What Makes a Kernel</li>
    <li>Support Vector Machines</li>
    <li>Understanding Support Vector Machines</li>
    <li>Kernelized Regression</li>
  </ul>
</li>
<li>
  Learning Theory <font size=-1>(4590 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain why inductive bias is necessary. </li>
        <li> Define the PAC model and explain why both the ``P'' and ``A'' are necessary. </li>
        <li> Explain the relationship between complexity measures and regularizers. </li>
        <li> Identify the role of complexity in generalization. </li>
        <li> Formalize the relationship between margins and complexity. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>The Role of Theory</li>
    <li>Induction is Impossible</li>
    <li>Probably Approximately Correct Learning</li>
    <li>PAC Learning of Conjunctions</li>
    <li>Occam's Razor: Simple Solutions Generalize</li>
    <li>Complexity of Infinite Hypothesis Spaces</li>
    <li>Learning with Noise</li>
    <li>Agnostic Learning</li>
    <li>Error versus Regret</li>
  </ul>
</li>
<li>
  Ensemble Methods <font size=-1>(2942 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Implement bagging and explain how it reduces variance in a predictor. % </li>
        <li> Show how to turn a binary classifier into a cost-sensitive % classifier through weighted bagging. </li>
        <li> Explain the difference between a weak learner and a strong learner. </li>
        <li> Derive the AdaBoost algorithm. </li>
        <li> Understand the relationship between boosting decision stumps and linear classification. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Voting Multiple Classifiers</li>
    <li>Boosting Weak Learners</li>
    <li>Random Ensembles</li>
  </ul>
</li>
<li>
  Efficient Learning <font size=-1>(2836 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Understand and be able to implement stochastic gradient descent algorithms. </li>
        <li> Compare and contrast small versus large batch sizes in stochastic optimization. </li>
        <li> Derive subgradients for sparse regularizers. </li>
        <li> Implement feature hashing. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>What Does it Mean to be Fast?</li>
    <li>Stochastic Optimization</li>
    <li>Higher-Order Methods</li>
    <li>Sparse Regularization</li>
    <li>Feature Hashing</li>
  </ul>
</li>
<li>
  Unsupervised Learning <font size=-1>(3256 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain the difference between linear and non-linear dimensionality reduction. </li>
        <li> Relate the view of PCA as maximizing variance with the view of it as minimizing reconstruction error. </li>
        <li> Implement latent semantic analysis for text data. </li>
        <li> Motivate manifold learning from the perspective of reconstruction error. </li>
        <li> Understand K-means clustering as distance minimization. </li>
        <li> Explain the importance of initialization in k-means and furthest-first heuristic. </li>
        <li> Implement agglomerative clustering. </li>
        <li> Argue whether spectral clustering is a clustering algorithm or a dimensionality reduction algorithm. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>K-Means Clustering, Revisited</li>
    <li>Linear Dimensionality Reduction</li>
    <li>Manifolds and Graphs</li>
    <li>Non-linear Dimensionality Reduction</li>
    <li>Non-linear Clustering: Spectral Methods</li>
  </ul>
</li>
<li>
  Expectation Maximization <font size=-1>(1975 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain the relationship between parameters and hidden variables. </li>
        <li> Construct generative stories for clustering and dimensionality reduction. </li>
        <li> Draw a graph explaining how EM works by constructing convex lower bounds. </li>
        <li> Implement EM for clustering with mixtures of Gaussians, and contrasting it with k-means. </li>
        <li> Evaluate the differences betweem EM and gradient descent for hidden variable models. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Clustering with a Mixture of Gaussians</li>
    <li>The Expectation Maximization Framework</li>
    <li>EM versus Gradient Descent</li>
    <li>Dimensionality Reduction with Probabilistic PCA</li>
  </ul>
</li>
<li>
  Semi-Supervised Learning <font size=-1>(246 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain the cluster assumption for semi-supervised discriminative learning, and why it is necessary. </li>
        <li> Dervive an EM algorithm for generative semi-supervised text categorization. </li>
        <li> Compare and contrast the query by uncertainty and query by committee heuristics for active learning. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>EM for Semi-Supervised Learning</li>
    <li>Graph-based Semi-Supervised Learning</li>
    <li>Loss-based Semi-Supervised Learning</li>
    <li>Active Learning</li>
    <li>Dangers of Semi-Supervised Learing</li>
  </ul>
</li>
<li>
  Graphical Models <font size=-1>(36 words)</font>
</li>
<li>
  Online Learning <font size=-1>(202 words)</font>
  <span class="objectives">
    <font size="-2">[objectives]</font>
    <span>
      <ol>
        <li> Explain the experts model, and why it is hard even to compete with the single best expert. </li>
        <li> Define what it means for an online learning algorithm to have no regret. </li>
        <li> Implement the follow-the-leader algorithm. </li>
        <li> Categorize online learning algorithms in terms of how they measure changes in parameters, and how they measure error. </li>
      </ol>
    </span>
  </span>
  <ul>
    <li>Online Learning Framework</li>
    <li>Learning with Features</li>
    <li>Passive Agressive Learning</li>
    <li>Learning with Lots of Irrelevant Features</li>
  </ul>
</li>
<li>
  Structured Learning Tasks <font size=-1>(51 words)</font>
</li>
<li>
  Bayesian Learning <font size=-1>(24 words)</font>
</li>
<li>
  Code and Datasets <font size=-1>(277 words)</font>
</li>
<li>
  Notation <font size=-1>(13 words)</font>
</li>
</ol>
